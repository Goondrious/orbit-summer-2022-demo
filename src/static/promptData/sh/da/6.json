[[{"text":"Q. Give a few examples of features you might design for a chess-playing RL agent.\nA. e.g. whether you have your opponent in check, how many pawns you have left, whether one of your pieces is threatened","tags":[],"target":[{"selector":[{"type":"RangeSelector","startContainer":"/div[1]/p[12]","startOffset":0,"endContainer":"/div[1]/p[12]","endOffset":33},{"type":"TextPositionSelector","start":2266,"end":2299},{"type":"TextQuoteSelector","exact":"For example, in the game of chess","prefix":"changes in the value of a state.","suffix":", one such feature could be whet"}]}]},{"text":"Q. Give the mathematical form of a value function defined by linear combination of features.\nA. $\\hat v(s) = \\mathbf{w} \\cdot x(s)$ where $x(s)$ is the feature vector extracted from $s$ and $\\mathbf{w}$ is a learned parameter vector.","tags":[],"target":[{"selector":[{"type":"RangeSelector","startContainer":"/div[1]/p[20]","startOffset":0,"endContainer":"/div[1]/p[20]","endOffset":58},{"type":"TextPositionSelector","start":3995,"end":4053},{"type":"TextQuoteSelector","exact":"This is the same as a weighted sum of these feature terms:","prefix":"1​⋮wn​​⎦⎤​⋅⎣⎡​x1​(s)⋮xn​(s)​⎦⎤​\n","suffix":"@import url('https://cdnjs.cloud"}]}]},{"text":"Q. What do the learned parameters represent in a linear combination of features?\nA. The amount of value assigned to that feature.\n\nIf $w_i$ is large and positive, large values of $x_i$ correspond to the state having a high value $\\hat{v}(s)$.\n\nIf it's close to 0, that feature doesn't affect value much.","tags":[],"target":[{"selector":[{"type":"RangeSelector","startContainer":"/div[1]/p[21]","startOffset":11,"endContainer":"/div[1]/p[21]","endOffset":85},{"type":"TextPositionSelector","start":4239,"end":4313},{"type":"TextQuoteSelector","exact":"each parameter corresponds to the amount of value assigned to that feature","prefix":"w1​x1​(s)+⋯+wn​xn​(s)Therefore, ","suffix":".\nLinear in the parameters model"}]}]},{"text":"Q. What is a \"feature vector\" in RL?\nA. A compact representation of a set of features: each component represents the value of a single feature of that state.","tags":[],"target":[{"selector":[{"type":"RangeSelector","startContainer":"/div[1]/p[15]/span[1]","startOffset":0,"endContainer":"/div[1]/p[15]/span[5]","endOffset":14},{"type":"TextPositionSelector","start":2775,"end":2929},{"type":"TextQuoteSelector","exact":"Mathematically, this means representing the state as an @import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')nnn﻿-length vector","prefix":"is moving to the left or right.\n","suffix":"@import url('https://cdnjs.cloud"}]}]},{"text":"Q. How can a linear combination of features approximate a non-linear function?\nA. The features themselves can be non-linear (e.g. 0/1 binary values or more complex functions).","tags":[],"target":[{"selector":[{"type":"RangeSelector","startContainer":"/div[1]/div[1]/p[1]","startOffset":0,"endContainer":"/div[1]/div[1]/p[1]","endOffset":64},{"type":"TextPositionSelector","start":4438,"end":4502},{"type":"TextQuoteSelector","exact":"No, because the we have full control over the features we design","prefix":"an approximate to linear models?","suffix":". These can be non-linear. Mathe"}]}]},{"text":"Q. How do feature-based value functions help our models generalize to unseen states?\nA. If an unseen state has the same features as a seen state, it will have the same approximated value.","tags":[],"target":[{"selector":[{"type":"RangeSelector","startContainer":"/div[1]/p[5]","startOffset":200,"endContainer":"/div[1]/p[5]","endOffset":301},{"type":"TextPositionSelector","start":1161,"end":1262},{"type":"TextQuoteSelector","exact":"Also, by comparing states based on their features, generalisation to unseen states is straightforward","prefix":"he number of parameters needed. ","suffix":". However, this relies on the de"}]}]},{"text":"Q. When approximating a value function using feature table lookup, what is the structure of the lookup table?\nA. The table is a mapping from feature vector to value estimate.\n\nE.g. in Python: `{feature: value}`.","tags":[],"target":[{"selector":[{"type":"RangeSelector","startContainer":"/div[1]/ul[2]/li[1]/details[1]/p[1]","startOffset":0,"endContainer":"/div[1]/ul[2]/li[1]/details[1]/p[1]","endOffset":82},{"type":"TextPositionSelector","start":6943,"end":7025},{"type":"TextQuoteSelector","exact":"You can represent this as a Python dictionary with {feature_vector: value} mapping","prefix":"e feature vector value.\nIn code…","suffix":", rather than {state: value} whi"}]}]},{"text":"Q. Why might one want to use feature vectors rather than states in lookup tables? (at least 2 reasons)\nA. e.g. Learned values will generalize to all states with matching feature vectors, and the space of feature vectors is much smaller than the state space.","tags":[],"target":[{"selector":[{"type":"RangeSelector","startContainer":"/div[1]/p[29]","startOffset":113,"endContainer":"/div[1]/p[29]","endOffset":227},{"type":"TextPositionSelector","start":5152,"end":5266},{"type":"TextQuoteSelector","exact":"Unlike normal lookup tables, you don't have values for all possible states, but for different feature combinations","prefix":"kup tables and feature vectors. ","suffix":".For example, in Tic-Tac-Toe, tw"}]}]},{"text":"Q. When extracting features to approximate the value function, features are extracted [stochastically/deterministically] from the [state/reward].\n\nA. Features are extracted deterministically from the state.","tags":[],"target":[{"selector":[{"type":"RangeSelector","startContainer":"/div[1]/p[11]","startOffset":126,"endContainer":"/div[1]/p[11]","endOffset":297},{"type":"TextPositionSelector","start":1914,"end":2085},{"type":"TextQuoteSelector","exact":"These features (usually grouped in a feature vector) are hand-crafted by a designer, who writes a deterministic function to extract salient features from the current state","prefix":"parameter values with features. ","suffix":". It's up to the designer (you) "}]}]}]]